# Efficient-Batch-Processed-Q-A-with-Gemini-Context-Caching-RAG

This is an offline-ready local demo of the batch prediction + context caching pipeline from the GSoC DeepMind [proposal](https://gist.github.com/dynamicwebpaige/92f7739ad69d2863ac7e2032fe52fbad#4-batch-prediction-with-long-context-and-context-caching-code-sample-).

## How to Run

```bash
poetry install
poetry run python src
```
