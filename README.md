# Efficient-Batch-Processed-Q-A-with-Gemini-Context-Caching-RAG

This is an offline-ready local demo of the batch prediction + context caching pipeline from the GSoC DeepMind proposal.

## How to Run

```bash
poetry install
poetry run python src/pipeline.py
```
